{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pip install catboost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pip install xgboost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 24>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m confusion_matrix\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mensemble\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GradientBoostingClassifier,AdaBoostClassifier\n\u001B[0;32m---> 24\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mxgboost\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mxgb\u001B[39;00m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m plot_confusion_matrix\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import librosa\n",
    "import os\n",
    "import csv\n",
    "import sklearn.cluster\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, preprocessing, metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier,AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from catboost import CatBoostClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bef36aaf-15e9-487e-8521-bf5668956593",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def kmedoids(y, n):#n: number of cluster, y: data\n",
    "    y = y.flatten()\n",
    "    y = y.reshape(-1, 1) #convert 1d array\n",
    "    kmedoid = KMedoids(n_clusters = n).fit(y)\n",
    "    first = []\n",
    "    second = []\n",
    "    if n == 2 :\n",
    "        for i in range (0, len(y)):\n",
    "            if kmedoid.labels_[i] == 0 :\n",
    "                first.append(y[i])\n",
    "            elif kmedoid.labels_[i] == 1 :\n",
    "                second.append(y[i])\n",
    "        first = np.array(first).reshape(1, -1)\n",
    "        second = np.array(second).reshape(1, -1)\n",
    "        return first, second\n",
    "    elif n == 3 :\n",
    "        third = []\n",
    "        for i in range (0, len(y)):\n",
    "            if kmedoid.labels_[i] == 0 :\n",
    "                first.append(y[i])\n",
    "            elif kmedoid.labels_[i] == 1 :\n",
    "                second.append(y[i])\n",
    "            elif kmedoid.labels_[i] == 2 :\n",
    "                third.append(y[i])\n",
    "        first = np.array(first).reshape(1, -1)\n",
    "        second = np.array(second).reshape(1, -1)\n",
    "        third = np.array(third).reshape(1, -1)\n",
    "        return np.array(first), np.array(second), np.array(third)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86a3ad9e-bb69-47e8-882a-798b77a18e0a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def hierarchical(y, n):\n",
    "    y = y.flatten()\n",
    "    y = y.reshape(-1, 1)\n",
    "    cluster = AgglomerativeClustering(n_clusters = n,\n",
    "                                  affinity = \"euclidean\", #distance metric\n",
    "                                  linkage = \"ward\")\n",
    "    labels = np.array(cluster.fit_predict(y))\n",
    "    first = []\n",
    "    second = []\n",
    "    if n == 2 :\n",
    "        for i in range (0, len(y)):\n",
    "            if labels[i] == 0 :\n",
    "                first.append(y[i])\n",
    "            elif labels[i] == 1 :\n",
    "                second.append(y[i])\n",
    "        first = np.array(first).reshape(1, -1)\n",
    "        second = np.array(second).reshape(1, -1)\n",
    "        return first, second\n",
    "    elif n == 3 :\n",
    "        third = []\n",
    "        for i in range (0, len(y)):\n",
    "            if labels[i] == 0 :\n",
    "                first.append(y[i])\n",
    "            elif labels[i] == 1 :\n",
    "                second.append(y[i])\n",
    "            elif labels[i] == 2 :\n",
    "                third.append(y[i])\n",
    "        first = np.array(first).reshape(1, -1)\n",
    "        second = np.array(second).reshape(1, -1)\n",
    "        third = np.array(third).reshape(1, -1)\n",
    "        return np.array(first), np.array(second), np.array(third)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1ffc47d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def gaussian_mixture(y, n):\n",
    "    y = y.flatten()\n",
    "    y = y.reshape(-1, 1)\n",
    "    cluster = sklearn.mixture.GaussianMixture(n_components = n).fit(y)\n",
    "    labels = np.array(cluster.predict(y))\n",
    "    first = []\n",
    "    second = []\n",
    "    if n == 2 :\n",
    "        for i in range (0, len(y)):\n",
    "            if labels[i] == 0 :\n",
    "                first.append(y[i])\n",
    "            elif labels[i] == 1 :\n",
    "                second.append(y[i])\n",
    "        first = np.array(first).reshape(1, -1)\n",
    "        second = np.array(second).reshape(1, -1)\n",
    "        return first, second\n",
    "    elif n == 3 :\n",
    "        third = []\n",
    "        for i in range (0, len(y)):\n",
    "            if labels[i] == 0 :\n",
    "                first.append(y[i])\n",
    "            elif labels[i] == 1 :\n",
    "                second.append(y[i])\n",
    "            elif labels[i] == 2 :\n",
    "                third.append(y[i])\n",
    "        first = np.array(first).reshape(1, -1)\n",
    "        second = np.array(second).reshape(1, -1)\n",
    "        third = np.array(third).reshape(1, -1)\n",
    "        return np.array(first), np.array(second), np.array(third)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa6708bc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def statistics(arr):\n",
    "    try:\n",
    "        arr = np.array(arr).flatten()\n",
    "        mean = np.mean(arr)\n",
    "        std_dev = np.std(arr)\n",
    "        median = np.median(arr)\n",
    "        minn = np.min(arr)\n",
    "        maxx = np.max(arr)\n",
    "        skewness = sp.stats.skew(arr)\n",
    "        kurtosis = sp.stats.kurtosis(arr)\n",
    "    except ValueError:\n",
    "        return '0 0 0 0 0 0 0'\n",
    "    x =f'{mean} {std_dev} {median} {minn} {maxx} {skewness} {kurtosis}'\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea31356d-52ce-43c5-b37d-351c7a04454d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def feature_extraction_clusteringKM_3(y, sr):\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    chroma_cqt = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    spec_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    spec_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr)#signal processing part so far\n",
    "    \n",
    "    first_stft, second_stft, third_stft = kmedoids(chroma_stft, 3)\n",
    "    first_cqt, second_cqt, third_cqt = kmedoids(chroma_cqt, 3)\n",
    "    first_cent, second_cent, third_cent = kmedoids(spec_cent, 3)\n",
    "    first_bw, second_bw, third_bw = kmedoids(spec_bw, 3)\n",
    "    first_cont, second_cont, third_cont = kmedoids(spec_contrast, 3)\n",
    "    first_rolloff, second_rolloff, third_rolloff = kmedoids(spec_rolloff, 3)\n",
    "    first_zcr, second_zcr, third_zcr = kmedoids(zcr, 3)\n",
    "    first_rms, second_rms, third_rms = kmedoids(rms, 3)#clustering of vectors\n",
    "    \n",
    "    s_first_stft = statistics(first_stft)\n",
    "    s_second_stft = statistics(second_stft)\n",
    "    s_third_stft = statistics(third_stft )\n",
    "    s_first_cqt = statistics(first_cqt)\n",
    "    s_second_cqt = statistics(second_cqt)\n",
    "    s_third_cqt = statistics(third_cqt)\n",
    "    s_first_cent = statistics(first_cent)\n",
    "    s_second_cent = statistics(second_cent)\n",
    "    s_third_cent = statistics(third_cent)\n",
    "    s_first_bw = statistics(first_bw)\n",
    "    s_second_bw = statistics(second_bw)\n",
    "    s_third_bw = statistics(third_bw)\n",
    "    s_first_cont = statistics(first_cont)\n",
    "    s_second_cont = statistics(second_cont)\n",
    "    s_third_cont = statistics(third_cont)\n",
    "    s_first_rolloff = statistics(first_rolloff)\n",
    "    s_second_rolloff = statistics(second_rolloff) \n",
    "    s_third_rolloff = statistics(third_rolloff)\n",
    "    first_zcr = statistics(first_zcr)\n",
    "    second_zcr = statistics(second_zcr)\n",
    "    third_zcr = statistics(third_zcr)\n",
    "    first_rms = statistics(first_rms)\n",
    "    second_rms = statistics(second_rms)\n",
    "    third_rms = statistics(third_rms)\n",
    "    mfccs = \"\"\n",
    "    for mfcc_ite in mfcc:\n",
    "        first_mfcc, second_mfcc, third_mfcc = kmedoids(mfcc_ite, 3)\n",
    "        mfccs += statistics(first_mfcc)\n",
    "        mfccs += \" \"\n",
    "        mfccs += statistics(second_mfcc)\n",
    "        mfccs += \" \"\n",
    "        mfccs += statistics(third_mfcc)\n",
    "        mfccs += \" \"\n",
    "\n",
    "\n",
    "    mfccs = mfccs.rstrip(mfccs[-1])#delete last space\n",
    "    \n",
    "    return s_first_stft, s_second_stft, s_third_stft, s_first_cqt, s_second_cqt, s_third_cqt, s_first_cent, s_second_cent, \\\n",
    "    s_third_cent, s_first_bw, s_second_bw, s_third_bw, s_first_cont, s_second_cont, s_third_cont, s_first_rolloff, \\\n",
    "    s_second_rolloff, s_third_rolloff, first_rms, second_rms, third_rms, first_zcr, second_zcr, third_zcr, mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def feature_extraction_clusteringKM_2(y, sr):\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    chroma_cqt = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    spec_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    spec_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "\n",
    "    first_stft, second_stft = kmedoids(chroma_stft, 2)\n",
    "    first_cqt, second_cqt = kmedoids(chroma_cqt, 2)\n",
    "    first_cent, second_cent = kmedoids(spec_cent, 2)\n",
    "    first_bw, second_bw = kmedoids(spec_bw, 2)\n",
    "    first_rolloff, second_rolloff = kmedoids(spec_rolloff, 2)\n",
    "    first_cont, second_cont = kmedoids(spec_contrast, 2)\n",
    "    first_zcr, second_zcr = kmedoids(zcr, 2)\n",
    "    first_rms, second_rms = kmedoids(rms, 2)\n",
    "\n",
    "    s_first_stft = statistics(first_stft)\n",
    "    s_second_stft = statistics(second_stft)\n",
    "    s_first_cqt = statistics(first_cqt)\n",
    "    s_second_cqt = statistics(second_cqt)\n",
    "    s_first_cent = statistics(first_cent)\n",
    "    s_second_cent = statistics(second_cent)\n",
    "    s_first_bw = statistics(first_bw)\n",
    "    s_second_bw = statistics(second_bw)\n",
    "    s_first_cont = statistics(first_cont)\n",
    "    s_second_cont = statistics(second_cont)\n",
    "    s_first_rolloff = statistics(first_rolloff)\n",
    "    s_second_rolloff = statistics(second_rolloff)\n",
    "    s_first_zcr = statistics(first_zcr)\n",
    "    s_second_zcr = statistics(second_zcr)\n",
    "    s_first_rms = statistics(first_rms)\n",
    "    s_second_rms = statistics(second_rms)\n",
    "\n",
    "    mfccs = \"\"\n",
    "    for mfcc_ite in mfcc:\n",
    "        first_mfcc, second_mfcc = kmedoids(mfcc_ite, 2)\n",
    "        mfccs += statistics(first_mfcc)\n",
    "        mfccs += \" \"\n",
    "        mfccs += statistics(second_mfcc)\n",
    "        mfccs += \" \"\n",
    "\n",
    "\n",
    "    mfccs = mfccs.rstrip(mfccs[-1])#delete last space\n",
    "\n",
    "    return s_first_stft, s_second_stft, s_first_cqt, s_second_cqt, s_first_cent, s_second_cent, s_first_bw, s_second_bw, s_first_cont, s_second_cont \\\n",
    "    , s_first_rolloff, s_second_rolloff, s_first_rms, s_second_rms,s_first_zcr, s_second_zcr,mfccs\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5f48e70",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def feature_extraction_clusteringHR_3(y, sr):\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    chroma_cqt = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    spec_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    spec_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "\n",
    "    first_stft, second_stft, third_stft = hierarchical(chroma_stft, 3)\n",
    "    first_cqt, second_cqt, third_cqt = hierarchical(chroma_cqt, 3)\n",
    "    first_cent, second_cent, third_cent = hierarchical(spec_cent, 3)\n",
    "    first_bw, second_bw, third_bw = hierarchical(spec_bw, 3)\n",
    "    first_cont, second_cont, third_cont = hierarchical(spec_contrast, 3)\n",
    "    first_rolloff, second_rolloff, third_rolloff = hierarchical(spec_rolloff, 3)\n",
    "    first_zcr, second_zcr, third_zcr = hierarchical(zcr, 3)\n",
    "    first_rms, second_rms, third_rms = hierarchical(rms, 3)\n",
    "\n",
    "    s_first_stft = statistics(first_stft)\n",
    "    s_second_stft = statistics(second_stft)\n",
    "    s_third_stft = statistics(third_stft )\n",
    "    s_first_cqt = statistics(first_cqt)\n",
    "    s_second_cqt = statistics(second_cqt)\n",
    "    s_third_cqt = statistics(third_cqt)\n",
    "    s_first_cent = statistics(first_cent)\n",
    "    s_second_cent = statistics(second_cent)\n",
    "    s_third_cent = statistics(third_cent)\n",
    "    s_first_bw = statistics(first_bw)\n",
    "    s_second_bw = statistics(second_bw)\n",
    "    s_third_bw = statistics(third_bw)\n",
    "    s_first_cont = statistics(first_cont)\n",
    "    s_second_cont = statistics(second_cont)\n",
    "    s_third_cont = statistics(third_cont)\n",
    "    s_first_rolloff = statistics(first_rolloff)\n",
    "    s_second_rolloff = statistics(second_rolloff)\n",
    "    s_third_rolloff = statistics(third_rolloff)\n",
    "    first_zcr = statistics(first_zcr)\n",
    "    second_zcr = statistics(second_zcr)\n",
    "    third_zcr = statistics(third_zcr)\n",
    "    first_rms = statistics(first_rms)\n",
    "    second_rms = statistics(second_rms)\n",
    "    third_rms = statistics(third_rms)\n",
    "    mfccs = \"\"\n",
    "    for mfcc_ite in mfcc:\n",
    "        first_mfcc, second_mfcc, third_mfcc = hierarchical(mfcc_ite, 3)\n",
    "        mfccs += statistics(first_mfcc)\n",
    "        mfccs += \" \"\n",
    "        mfccs += statistics(second_mfcc)\n",
    "        mfccs += \" \"\n",
    "        mfccs += statistics(third_mfcc)\n",
    "        mfccs += \" \"\n",
    "\n",
    "\n",
    "    mfccs = mfccs.rstrip(mfccs[-1])#delete last space\n",
    "\n",
    "    return s_first_stft, s_second_stft, s_third_stft, s_first_cqt, s_second_cqt, s_third_cqt, s_first_cent, s_second_cent, \\\n",
    "    s_third_cent, s_first_bw, s_second_bw, s_third_bw, s_first_cont, s_second_cont, s_third_cont, s_first_rolloff, \\\n",
    "    s_second_rolloff, s_third_rolloff, first_rms, second_rms, third_rms, first_zcr, second_zcr, third_zcr, mfccs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "295b794b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def feature_extraction_clusteringHR_2(y, sr):\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    chroma_cqt = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    spec_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    spec_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "\n",
    "    first_stft, second_stft = hierarchical(chroma_stft, 2)\n",
    "    first_cqt, second_cqt = hierarchical(chroma_cqt, 2)\n",
    "    first_cent, second_cent = hierarchical(spec_cent, 2)\n",
    "    first_bw, second_bw = hierarchical(spec_bw, 2)\n",
    "    first_rolloff, second_rolloff = hierarchical(spec_rolloff, 2)#anlamadığım sebepten dolayı kmedoids ile bölünemiyordu\n",
    "    first_cont, second_cont = hierarchical(spec_contrast, 2)\n",
    "    first_zcr, second_zcr = hierarchical(zcr, 2)\n",
    "    first_rms, second_rms = hierarchical(rms, 2)\n",
    "\n",
    "    s_first_stft = statistics(first_stft)\n",
    "    s_second_stft = statistics(second_stft)\n",
    "    s_first_cqt = statistics(first_cqt)\n",
    "    s_second_cqt = statistics(second_cqt)\n",
    "    s_first_cent = statistics(first_cent)\n",
    "    s_second_cent = statistics(second_cent)\n",
    "    s_first_bw = statistics(first_bw)\n",
    "    s_second_bw = statistics(second_bw)\n",
    "    s_first_cont = statistics(first_cont)\n",
    "    s_second_cont = statistics(second_cont)\n",
    "    s_first_rolloff = statistics(first_rolloff)\n",
    "    s_second_rolloff = statistics(second_rolloff)\n",
    "    s_first_zcr = statistics(first_zcr)\n",
    "    s_second_zcr = statistics(second_zcr)\n",
    "    s_first_rms = statistics(first_rms)\n",
    "    s_second_rms = statistics(second_rms)\n",
    "\n",
    "    mfccs = \"\"\n",
    "    for mfcc_ite in mfcc:\n",
    "        first_mfcc, second_mfcc = hierarchical(mfcc_ite, 2)\n",
    "        mfccs += statistics(first_mfcc)\n",
    "        mfccs += \" \"\n",
    "        mfccs += statistics(second_mfcc)\n",
    "        mfccs += \" \"\n",
    "\n",
    "\n",
    "    mfccs = mfccs.rstrip(mfccs[-1])#delete last space\n",
    "\n",
    "    return s_first_stft, s_second_stft, s_first_cqt, s_second_cqt, s_first_cent, s_second_cent, s_first_bw, s_second_bw, s_first_cont, s_second_cont \\\n",
    "    , s_first_rolloff, s_second_rolloff, s_first_rms, s_second_rms,s_first_zcr, s_second_zcr,mfccs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def feature_extraction_clusteringGM_3(y, sr):\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    chroma_cqt = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    spec_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    spec_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "\n",
    "    first_stft, second_stft, third_stft = gaussian_mixture(chroma_stft, 3)\n",
    "    first_cqt, second_cqt, third_cqt = gaussian_mixture(chroma_cqt, 3)\n",
    "    first_cent, second_cent, third_cent = gaussian_mixture(spec_cent, 3)\n",
    "    first_bw, second_bw, third_bw = gaussian_mixture(spec_bw, 3)\n",
    "    first_cont, second_cont, third_cont = gaussian_mixture(spec_contrast, 3)\n",
    "    first_rolloff, second_rolloff, third_rolloff = gaussian_mixture(spec_rolloff, 3)\n",
    "    first_zcr, second_zcr, third_zcr = gaussian_mixture(zcr, 3)\n",
    "    first_rms, second_rms, third_rms = gaussian_mixture(rms, 3)\n",
    "\n",
    "    s_first_stft = statistics(first_stft)\n",
    "    s_second_stft = statistics(second_stft)\n",
    "    s_third_stft = statistics(third_stft )\n",
    "    s_first_cqt = statistics(first_cqt)\n",
    "    s_second_cqt = statistics(second_cqt)\n",
    "    s_third_cqt = statistics(third_cqt)\n",
    "    s_first_cent = statistics(first_cent)\n",
    "    s_second_cent = statistics(second_cent)\n",
    "    s_third_cent = statistics(third_cent)\n",
    "    s_first_bw = statistics(first_bw)\n",
    "    s_second_bw = statistics(second_bw)\n",
    "    s_third_bw = statistics(third_bw)\n",
    "    s_first_cont = statistics(first_cont)\n",
    "    s_second_cont = statistics(second_cont)\n",
    "    s_third_cont = statistics(third_cont)\n",
    "    s_first_rolloff = statistics(first_rolloff)\n",
    "    s_second_rolloff = statistics(second_rolloff)\n",
    "    s_third_rolloff = statistics(third_rolloff)\n",
    "    first_zcr = statistics(first_zcr)\n",
    "    second_zcr = statistics(second_zcr)\n",
    "    third_zcr = statistics(third_zcr)\n",
    "    first_rms = statistics(first_rms)\n",
    "    second_rms = statistics(second_rms)\n",
    "    third_rms = statistics(third_rms)\n",
    "    mfccs = \"\"\n",
    "    for mfcc_ite in mfcc:\n",
    "        first_mfcc, second_mfcc, third_mfcc = gaussian_mixture(mfcc_ite, 2)\n",
    "        mfccs += statistics(first_mfcc)\n",
    "        mfccs += \" \"\n",
    "        mfccs += statistics(second_mfcc)\n",
    "        mfccs += \" \"\n",
    "        mfccs += statistics(third_mfcc)\n",
    "        mfccs += \" \"\n",
    "\n",
    "\n",
    "    mfccs = mfccs.rstrip(mfccs[-1])#delete last space\n",
    "\n",
    "    return s_first_stft, s_second_stft, s_third_stft, s_first_cqt, s_second_cqt, s_third_cqt, s_first_cent, s_second_cent, \\\n",
    "    s_third_cent, s_first_bw, s_second_bw, s_third_bw, s_first_cont, s_second_cont, s_third_cont, s_first_rolloff, \\\n",
    "    s_second_rolloff, s_third_rolloff, first_rms, second_rms, third_rms, first_zcr, second_zcr, third_zcr, mfccs\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33a087c0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def feature_extraction_clusteringGM_2(y, sr):\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    chroma_cqt = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    spec_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    spec_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "\n",
    "    first_stft, second_stft = gaussian_mixture(chroma_stft, 2)\n",
    "    first_cqt, second_cqt = gaussian_mixture(chroma_cqt, 2)\n",
    "    first_cent, second_cent = gaussian_mixture(spec_cent, 2)\n",
    "    first_bw, second_bw = gaussian_mixture(spec_bw, 2)\n",
    "    first_rolloff, second_rolloff = gaussian_mixture(spec_rolloff, 2)\n",
    "    first_cont, second_cont = gaussian_mixture(spec_contrast, 2)\n",
    "    first_zcr, second_zcr = gaussian_mixture(zcr, 2)\n",
    "    first_rms, second_rms = gaussian_mixture(rms, 2)\n",
    "\n",
    "    s_first_stft = statistics(first_stft)\n",
    "    s_second_stft = statistics(second_stft)\n",
    "    s_first_cqt = statistics(first_cqt)\n",
    "    s_second_cqt = statistics(second_cqt)\n",
    "    s_first_cent = statistics(first_cent)\n",
    "    s_second_cent = statistics(second_cent)\n",
    "    s_first_bw = statistics(first_bw)\n",
    "    s_second_bw = statistics(second_bw)\n",
    "    s_first_cont = statistics(first_cont)\n",
    "    s_second_cont = statistics(second_cont)\n",
    "    s_first_rolloff = statistics(first_rolloff)\n",
    "    s_second_rolloff = statistics(second_rolloff)\n",
    "    s_first_zcr = statistics(first_zcr)\n",
    "    s_second_zcr = statistics(second_zcr)\n",
    "    s_first_rms = statistics(first_rms)\n",
    "    s_second_rms = statistics(second_rms)\n",
    "\n",
    "    mfccs = \"\"\n",
    "    for mfcc_ite in mfcc:\n",
    "        first_mfcc, second_mfcc = gaussian_mixture(mfcc_ite, 2)\n",
    "        mfccs += statistics(first_mfcc)\n",
    "        mfccs += \" \"\n",
    "        mfccs += statistics(second_mfcc)\n",
    "        mfccs += \" \"\n",
    "\n",
    "\n",
    "    mfccs = mfccs.rstrip(mfccs[-1])#delete last space\n",
    "\n",
    "    return s_first_stft, s_second_stft, s_first_cqt, s_second_cqt, s_first_cent, s_second_cent, s_first_bw, s_second_bw, s_first_cont, s_second_cont \\\n",
    "    , s_first_rolloff, s_second_rolloff, s_first_rms, s_second_rms,s_first_zcr, s_second_zcr,mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e02d48f4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def feature_extraction_no_clustering(y, sr):\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    chroma_cqt = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    spec_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    spec_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "\n",
    "\n",
    "    s_stft = statistics(chroma_stft)\n",
    "    s_cqt = statistics(chroma_cqt)\n",
    "    s_cent = statistics(spec_cent)\n",
    "    s_bw = statistics(spec_bw)\n",
    "    s_rollof = statistics(spec_rolloff)\n",
    "    s_cont = statistics(spec_contrast)\n",
    "    s_zcr = statistics(zcr)\n",
    "    s_rms = statistics(rms)\n",
    "\n",
    "    mfccs= statistics(mfcc[0,:])\n",
    "    for i in range(1, 20):\n",
    "        mfccs += statistics(mfcc[i,:])\n",
    "        mfccs += \" \"\n",
    "    mfccs = mfccs.rstrip(mfccs[-1])#delete last space\n",
    "    \n",
    "    \n",
    "    return s_stft, s_cqt, s_cent, s_bw, s_rollof, s_cont, s_zcr, s_rms, mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1acbb8c3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_csv(n, filename): \n",
    "    if n == 1:#it means no clustering just one cluster\n",
    "        header = 'chroma_stft_mean chroma_stft_std_dev chroma_stft_median chroma_stft_min chroma_stft_max chroma_stft_skewness chroma_stft_kurtosis'\n",
    "        header += ' chroma_cqt_mean chroma_cqt_std_dev chroma_cqt_median chroma_cqt_min chroma_cqt_max chroma_cqt_skewness chroma_cqt_kurtosis'\n",
    "        header += ' spec_cent_mean spec_cent_std_dev spec_cent_median spec_cent_min spec_cent_max spec_cent_skewness spec_cent_kurtosis'\n",
    "        header += ' spec_bw_mean spec_bw_std_dev spec_bw_median spec_bw_min spec_bw_max spec_bw_skewness spec_bw_kurtosis'\n",
    "        header += ' spec_rollof_mean spec_rollof_std_dev spec_rollof_median spec_rollof_min spec_rollof_max spec_rollof_skewness spec_rollof_kurtosis'\n",
    "        header += ' spec_contrast_mean spec_contrast_std_dev spec_contrast_median spec_contrast_min spec_contrast_max spec_contrast_skewness spec_contrast_kurtosis'\n",
    "        header += ' zcr_mean zcr_std_dev zcr_median zcr_min zcr_max zcr_skewness zcr_kurtosis'\n",
    "        header += ' rms_mean rms_std_dev rms_median rms_min rms_max rms_skewness rms_kurtosis'\n",
    "#header dedigim csvde attribute isimleri, ornekler write csv de\n",
    "        for i in range(1, 21):\n",
    "            header += f' mfcc_mean{i}'\n",
    "            header += f' mfcc_std_dev{i}'\n",
    "            header += f' mfcc_median{i}'\n",
    "            header += f' mfcc_min{i}'\n",
    "            header += f' mfcc_max{i}'\n",
    "            header += f' mfcc_skewness{i}'\n",
    "            header += f' mfcc_kurtosis{i}'\n",
    "        header += ' label'\n",
    "        header = header.split() #splits the str with space if no parameter\n",
    "\n",
    "        file = open(filename, 'w', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(header)\n",
    "    elif n > 1:\n",
    "        header = 'chroma_stft_mean0 chroma_stft_std_dev0 chroma_stft_median0 chroma_stft_min0 chroma_stft_max0 chroma_stft_skewness0 chroma_stft_kurtosis0'\n",
    "        for j in range (1,n):\n",
    "            header += f' chroma_stft_mean{j} chroma_stft_std_dev{j} chroma_stft_median{j} chroma_stft_min{j} chroma_stft_max{j} chroma_stft_skewness{j} chroma_stft_kurtosis{j}'\n",
    "        for j in range (0,n):    \n",
    "            header += f' chroma_cqt_mean{j} chroma_cqt_std_dev{j} chroma_cqt_median{j} chroma_cqt_min{j} chroma_cqt_max{j} chroma_cqt_skewness{j} chroma_cqt_kurtosis{j}'\n",
    "        for j in range (0,n):    \n",
    "            header += f' spec_cent_mean{j} spec_cent_std_dev{j} spec_cent_median{j} spec_cent_min{j} spec_cent_max{j} spec_cent_skewness{j} spec_cent_kurtosis{j}'\n",
    "        for j in range (0,n):    \n",
    "            header += f' spec_bw_mean{j} spec_bw_std_dev{j} spec_bw_median{j} spec_bw_min{j} spec_bw_max{j} spec_bw_skewness{j} spec_bw_kurtosis{j}'\n",
    "        for j in range (0,n):    \n",
    "            header += f' spec_rollof_mean{j} spec_rollof_std_dev{j} spec_rollof_median{j} spec_rollof_min{j} spec_rollof_max{j} spec_rollof_skewness{j} spec_rollof_kurtosis{j}'\n",
    "        for j in range (0,n):    \n",
    "            header += f' spec_contrast_mean{j} spec_contrast_std_dev{j} spec_contrast_median{j} spec_contrast_min{j} spec_contrast_max{j} spec_contrast_skewness{j} spec_contrast_kurtosis{j}'\n",
    "        for j in range (0,n):    \n",
    "            header += f' zcr_mean{j} zcr_std_dev{j} zcr_median{j} zcr_min{j} zcr_max{j} zcr_skewness{j} zcr_kurtosis{j}'\n",
    "        for j in range (0,n):\n",
    "            header += f' rms_mean{j} rms_std_dev{j} rms_median{j} rms_min{j} rms_max{j} rms_skewness{j} rms_kurtosis{j}'\n",
    "        for i in range(0, 20):\n",
    "            for j in range (0,n):\n",
    "                header += f' mfcc_mean{i}_{j} mfcc_std_dev{i}_{j} mfcc_median{i}_{j} mfcc_min{i}_{j} mfcc_max{i}_{j} mfcc_skewness{i}_{j} mfcc_kurtosis{i}_{j}'\n",
    "                \n",
    "        header += ' label'\n",
    "        header = header.split() #splits the str with space if no parameter\n",
    "\n",
    "        file = open(filename, 'w', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65b9111e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def write_csv_no_cluster(y, sr, song_genre, filename, feat_ext_func):#\n",
    "        s_stft, s_cqt, s_cent, s_bw, s_rollof, s_cont, s_zcr, s_rms, mfccs = feature_extraction_no_clustering(y,sr)\n",
    "        to_append = f'{s_stft} {s_cqt} {s_cent} {s_bw} {s_rollof} {s_cont} {s_zcr} {s_rms} {mfccs} '\n",
    "        to_append += song_genre\n",
    "        file = open(filename, 'a', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(to_append.split())        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d93a9fb5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def write_csv_cluster3(y, sr, song_genre, filename, feat_ext_func):# feat_ext_func = feature_extraction_clusteringHR_3 etc.\n",
    "    s_first_stft, s_second_stft, s_third_stft, s_first_cqt, s_second_cqt, s_third_cqt, s_first_cent, s_second_cent, \\\n",
    "    s_third_cent, s_first_bw, s_second_bw, s_third_bw, s_first_cont, s_second_cont, s_third_cont, s_first_rolloff, \\\n",
    "    s_second_rolloff, s_third_rolloff, first_rms, second_rms, third_rms, first_zcr, second_zcr, third_zcr, mfccs = feat_ext_func(y, sr)\n",
    "    to_append = f'{s_first_stft} {s_second_stft} {s_third_stft} {s_first_cqt} {s_second_cqt} {s_third_cqt} {s_first_cent} {s_second_cent} {s_third_cent} {s_first_bw} {s_second_bw} {s_third_bw}'\n",
    "    to_append += f' {s_first_cont} {s_second_cont} {s_third_cont} {s_first_rolloff} {s_second_rolloff} {s_third_rolloff} {first_rms} {second_rms} {third_rms} {first_zcr} {second_zcr} {third_zcr} {mfccs}'\n",
    "    to_append += f' {song_genre}'\n",
    "    file = open( filename, 'a', newline='')\n",
    "    with file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(to_append.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d697ca9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def write_csv_cluster2(y, sr, song_genre, filename, feat_ext_func):#feat_ext_func = feature_extraction_clusteringGM_2 etc.\n",
    "    s_first_stft, s_second_stft, s_first_cqt, s_second_cqt, s_first_cent, s_second_cent, s_first_bw, s_second_bw, s_first_cont, s_second_cont, s_first_rolloff, \\\n",
    "    s_second_rolloff, first_rms, second_rms,first_zcr, second_zcr, mfccs = feat_ext_func(y, sr)\n",
    "    to_append = f'{s_first_stft} {s_second_stft} {s_first_cqt} {s_second_cqt} {s_first_cent} {s_second_cent} {s_first_bw} {s_second_bw}'\n",
    "    to_append += f' {s_first_cont} {s_second_cont} {s_first_rolloff} {s_second_rolloff} {first_rms} {second_rms} {first_zcr} {second_zcr} {mfccs}'\n",
    "    to_append += f' {song_genre}'\n",
    "    file = open( filename, 'a', newline='')\n",
    "    with file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(to_append.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c70581",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#don't forget the change the path of the songs\n",
    "#the given feat_ext_func should be synchronize with the given n\n",
    "#feat_ext_func = feature_extraction_clusteringGM_2 etc.\n",
    "def dataset_maker(new_dataset, n, write_csv_func, feat_ext_func):#new_dataset = 'datasetDB2.csv' etc. and write_csv_func = write_csv_cluster3 or write_csv_no_cluster or write_csv_cluster2\n",
    "    genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "    create_csv(n, new_dataset)\n",
    "    for g in genres:\n",
    "        for filename in os.listdir(f'./parcalanmis/deneme/{g}/'):\n",
    "            songname = f'./parcalanmis/deneme/{g}/{filename}'\n",
    "            y, sr = librosa.load(songname, mono=True, duration=5)\n",
    "            write_csv_func( y, sr, g, new_dataset, feat_ext_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff31e08",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def read_and_learn(filename):\n",
    "  data = pd.read_csv(filename)\n",
    "  X, Y = data.iloc[:,:-1],data.iloc[:,-1]\n",
    "  scaler = preprocessing.MinMaxScaler((-1,1))\n",
    "  models = [DecisionTreeClassifier()]\n",
    "  models.append(GradientBoostingClassifier())\n",
    "  models.append(LogisticRegression(dual=False,multi_class='auto',solver='lbfgs'))\n",
    "  models.append(RandomForestClassifier(n_estimators=100,criterion='entropy'))\n",
    "  models.append(LinearDiscriminantAnalysis(solver='eigen', shrinkage='auto'))\n",
    "  models.append(KNeighborsClassifier(n_neighbors=1, weights='distance'))\n",
    "  models.append(SVC(C=100, kernel='rbf', degree=3, gamma=0.005))\n",
    "  models.append(GaussianNB())\n",
    "  models.append(CatBoostClassifier())\n",
    "  models.append(AdaBoostClassifier())\n",
    "  models.append(LinearSVC(penalty='l1', dual=False, multi_class='crammer_singer', max_iter=1000000))\n",
    "  models.append(xgb.XGBClassifier(objetive = \"multiclass:softmax\", num_class =10))\n",
    "  for model in models:\n",
    "      kf = model_selection.KFold(n_splits=10, shuffle=True)\n",
    "      Y = LabelEncoder().fit_transform(Y)\n",
    "      scaler.fit(X)\n",
    "      i = 0\n",
    "      total_acc = 0\n",
    "      total_pre = 0\n",
    "      total_recall = 0\n",
    "      total_f1 = 0\n",
    "      total_kappa = 0\n",
    "      t0 = time()\n",
    "      for train_index, test_index in kf.split(X):\n",
    "          x_train, x_test = X.iloc[train_index], X.iloc[test_index]\n",
    "          y_train, y_test = Y[train_index], Y[test_index]\n",
    "          x_train = scaler.transform(x_train)\n",
    "          x_test  = scaler.transform(x_test)\n",
    "          model.fit(x_train, y_train)\n",
    "          y_pred = model.predict(x_test)\n",
    "\n",
    "          pre = metrics.precision_score(y_test, y_pred, average = 'micro')\n",
    "          acc = metrics.accuracy_score(y_test, y_pred)\n",
    "          recall = metrics.recall_score(y_test, y_pred, average = 'micro')\n",
    "          f1 = metrics.f1_score(y_test, y_pred, average = 'micro')\n",
    "          kappa = metrics.cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "          total_pre += pre\n",
    "          total_acc += acc\n",
    "          total_recall += recall\n",
    "          total_f1 += f1\n",
    "          total_kappa += kappa\n",
    "          i+=1\n",
    "      total_time = time() - t0\n",
    "      print(f\"average accuracy: {total_acc/i}\")\n",
    "      print(f\"average precision: {total_pre/i}\")\n",
    "      print(f\"average recall: {total_recall/i}\")\n",
    "      print(f\"average f1 score: {total_f1/i}\")\n",
    "      print(f\"average Cohens Kappa: {total_kappa/i}\")\n",
    "      print(f\"total run time: {total_time}\")\n",
    "      plot_confusion_matrix(model, x_test, y_test)\n",
    "      plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}